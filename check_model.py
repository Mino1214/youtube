"""ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸"""

import os
from pathlib import Path
import sys

def check_model(model_path: str, model_name: str):
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸"""
    print(f"\n{'='*60}")
    print(f"ëª¨ë¸ í™•ì¸: {model_name}")
    print(f"ê²½ë¡œ: {model_path}")
    print(f"{'='*60}")
    
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
        return False
    
    # í•„ìˆ˜ íŒŒì¼ í™•ì¸
    required_files = [
        "config.json",
        "tokenizer_config.json",
        "tokenizer.json",
    ]
    
    # safetensors ë˜ëŠ” pytorch ëª¨ë¸ íŒŒì¼ í™•ì¸
    model_files = [
        "model.safetensors.index.json",  # safetensors ë¶„í•  ëª¨ë¸
        "model.safetensors",  # ë‹¨ì¼ safetensors íŒŒì¼
        "pytorch_model.bin.index.json",  # pytorch ë¶„í•  ëª¨ë¸
        "pytorch_model.bin",  # ë‹¨ì¼ pytorch ëª¨ë¸
    ]
    
    print("\n[í•„ìˆ˜ ì„¤ì • íŒŒì¼]")
    all_required = True
    for file in required_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"âœ… {file} ({size:,} bytes)")
        else:
            print(f"âŒ {file} - ëˆ„ë½ë¨")
            all_required = False
    
    print("\n[ëª¨ë¸ íŒŒì¼]")
    model_found = False
    total_size = 0
    
    # safetensors.index.json í™•ì¸
    index_file = os.path.join(model_path, "model.safetensors.index.json")
    if os.path.exists(index_file):
        print(f"âœ… model.safetensors.index.json ë°œê²¬")
        model_found = True
        
        # ë¶„í•  íŒŒì¼ í™•ì¸
        import json
        try:
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            weight_map = index_data.get("weight_map", {})
            unique_files = set(weight_map.values())
            
            print(f"\n[ë¶„í•  ëª¨ë¸ íŒŒì¼] ({len(unique_files)}ê°œ íŒŒì¼)")
            for i, filename in enumerate(sorted(unique_files), 1):
                file_path = os.path.join(model_path, filename)
                if os.path.exists(file_path):
                    size = os.path.getsize(file_path)
                    total_size += size
                    size_gb = size / (1024**3)
                    print(f"âœ… {filename} ({size_gb:.2f} GB)")
                else:
                    print(f"âŒ {filename} - ëˆ„ë½ë¨")
                    model_found = False
        except Exception as e:
            print(f"âš ï¸  index.json íŒŒì‹± ì˜¤ë¥˜: {e}")
    
    # ë‹¨ì¼ ëª¨ë¸ íŒŒì¼ í™•ì¸
    for file in model_files[1:]:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            total_size += size
            size_gb = size / (1024**3)
            print(f"âœ… {file} ({size_gb:.2f} GB)")
            model_found = True
            break
    
    if not model_found:
        print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë‹¤ìŒ ì¤‘ í•˜ë‚˜ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:")
        for file in model_files:
            print(f"   - {file}")
        return False
    
    # ì „ì²´ í¬ê¸° í‘œì‹œ
    if total_size > 0:
        total_gb = total_size / (1024**3)
        print(f"\nğŸ“¦ ì „ì²´ ëª¨ë¸ í¬ê¸°: {total_gb:.2f} GB")
    
    # ê¸°íƒ€ íŒŒì¼ í™•ì¸
    print("\n[ê¸°íƒ€ íŒŒì¼]")
    other_files = [
        "generation_config.json",
        "special_tokens_map.json",
        "vocab.json",
        "merges.txt",
    ]
    
    for file in other_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"âœ… {file} ({size:,} bytes)")
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    if all_required and model_found:
        print("âœ… ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        print("âŒ ëª¨ë¸ì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
        return False

def main():
    print("="*60)
    print("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸")
    print("="*60)
    
    # config.yamlì—ì„œ ëª¨ë¸ ê²½ë¡œ í™•ì¸
    config_path = "config.yaml"
    model_paths = []
    
    if os.path.exists(config_path):
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            llm_config = config.get("llm", {})
            model_path = llm_config.get("model_path")
            model_name = llm_config.get("model", "deepseek-r1-7b")
            
            if model_path:
                model_paths.append((model_path, model_name))
            else:
                # ê¸°ë³¸ ê²½ë¡œ í™•ì¸
                if model_name == "deepseek-r1-7b":
                    model_paths.append(("models/llm/deepseek-r1-7b", "DeepSeek-R1 7B"))
                elif model_name == "llama-3.1-8b":
                    model_paths.append(("models/llm/llama-3.1-8b", "Llama 3.1 8B"))
        except Exception as e:
            print(f"âš ï¸  config.yaml ì½ê¸° ì˜¤ë¥˜: {e}")
    
    # ê¸°ë³¸ ê²½ë¡œë“¤ í™•ì¸
    default_paths = [
        ("models/llm/deepseek-r1-7b", "DeepSeek-R1 7B"),
        ("models/llm/llama-3.1-8b", "Llama 3.1 8B"),
    ]
    
    # ì¤‘ë³µ ì œê±°
    all_paths = {}
    for path, name in model_paths + default_paths:
        if path not in all_paths:
            all_paths[path] = name
    
    if not all_paths:
        print("\nâŒ í™•ì¸í•  ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("\nìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•˜ë ¤ë©´:")
        print("python check_model.py <ëª¨ë¸_ê²½ë¡œ>")
        return 1
    
    # ê° ëª¨ë¸ í™•ì¸
    all_ok = True
    for model_path, model_name in all_paths.items():
        if os.path.exists(model_path):
            if not check_model(model_path, model_name):
                all_ok = False
        else:
            print(f"\nâš ï¸  ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
    
    # ìš”ì•½
    print("\n" + "="*60)
    if all_ok and any(os.path.exists(path) for path in all_paths.keys()):
        print("âœ… ëª¨ë“  ëª¨ë¸ì´ ì •ìƒì…ë‹ˆë‹¤!")
        return 0
    else:
        print("âŒ ì¼ë¶€ ëª¨ë¸ì´ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")
        return 1

if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ê²½ë¡œ ì§€ì • ê°€ëŠ¥
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
        model_name = sys.argv[2] if len(sys.argv) > 2 else "Custom Model"
        success = check_model(model_path, model_name)
        sys.exit(0 if success else 1)
    else:
        sys.exit(main())

