"""ëª¨ë“  í•„ìš”í•œ ëª¨ë¸ì„ ì°¾ê³  ìˆœì°¨ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸"""

import os
import sys
import subprocess
import argparse
from pathlib import Path
from typing import List, Dict, Optional
import yaml

def check_model_exists(model_path: str) -> bool:
    """ëª¨ë¸ì´ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not model_path:
        return False
    
    path = Path(model_path)
    if path.exists() and path.is_dir():
        # ë¡œì»¬ ê²½ë¡œì¸ ê²½ìš°: ëª¨ë¸ íŒŒì¼ê³¼ config íŒŒì¼ í™•ì¸
        model_files = list(path.rglob("*.safetensors")) + \
                     list(path.rglob("*.bin")) + \
                     list(path.rglob("*.onnx")) + \
                     list(path.rglob("*.pt")) + \
                     list(path.rglob("*.pth"))
        
        # config.jsonë„ í™•ì¸ (ëª¨ë¸ì´ ì™„ì „í•œì§€ í™•ì¸)
        config_file = path / "config.json"
        if len(model_files) > 0 and config_file.exists():
            return True
        return False
    
    # HuggingFace ìºì‹œ í™•ì¸
    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
    if cache_dir.exists():
        # ëª¨ë¸ IDì—ì„œ ê²½ë¡œ ì¶”ì •
        if "/" in model_path:
            model_name = model_path.replace("/", "--")
            cache_path = cache_dir / f"models--{model_name}"
            if cache_path.exists():
                # ìºì‹œ ë‚´ì—ì„œ ì‹¤ì œ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
                # HuggingFace ìºì‹œ êµ¬ì¡°: models--{name}/snapshots/{hash}/
                snapshots_dir = cache_path / "snapshots"
                if snapshots_dir.exists():
                    # ê°€ì¥ ìµœê·¼ ìŠ¤ëƒ…ìƒ· í™•ì¸
                    snapshots = list(snapshots_dir.iterdir())
                    if snapshots:
                        latest_snapshot = max(snapshots, key=lambda p: p.stat().st_mtime)
                        # ëª¨ë¸ íŒŒì¼ í™•ì¸
                        model_files = list(latest_snapshot.rglob("*.safetensors")) + \
                                     list(latest_snapshot.rglob("*.bin")) + \
                                     list(latest_snapshot.rglob("*.pt")) + \
                                     list(latest_snapshot.rglob("*.pth"))
                        config_file = latest_snapshot / "config.json"
                        # ëª¨ë¸ íŒŒì¼ê³¼ configê°€ ëª¨ë‘ ìˆì–´ì•¼ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                        if len(model_files) > 0 and config_file.exists():
                            return True
                # snapshotsê°€ ì—†ìœ¼ë©´ ì•„ì§ ë‹¤ìš´ë¡œë“œ ì¤‘ì´ê±°ë‚˜ ë¶ˆì™„ì „
                return False
    
    return False

def check_whisper_model(model_name: str) -> bool:
    """Whisper ëª¨ë¸ í™•ì¸"""
    try:
        import whisper
        cache_dir = whisper._MODELS
        model_path = os.path.join(cache_dir, f"{model_name}.pt")
        return os.path.exists(model_path)
    except:
        return False

def check_piper_voice(voice_name: str) -> bool:
    """Piper ìŒì„± ëª¨ë¸ í™•ì¸ (ê¸°ì¡´ rhasspy ëª¨ë¸)"""
    # ì˜ì–´ TTS ëª¨ë¸ (en_US-amy-medium) íŠ¹ë³„ ì²˜ë¦¬
    if voice_name == "en_US-amy-medium":
        # HuggingFace ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        hf_cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
        hf_model_dir = hf_cache_dir / "models--rhasspy--piper-voices"
        hf_paths = []
        if hf_model_dir.exists():
            snapshots_dir = hf_model_dir / "snapshots"
            if snapshots_dir.exists():
                snapshots = list(snapshots_dir.iterdir())
                if snapshots:
                    latest_snapshot = max(snapshots, key=lambda p: p.stat().st_mtime)
                    hf_paths.append(latest_snapshot / "en" / "en_US" / "amy" / "medium" / f"{voice_name}.onnx")
                    hf_paths.append(latest_snapshot / "en" / "en_US" / "amy" / "medium" / "model.onnx")
        
        possible_paths = hf_paths + [
            Path.home() / ".local" / "share" / "piper" / "voices" / "en" / "en_US" / "amy" / "medium" / f"{voice_name}.onnx",
            Path.home() / ".local" / "share" / "piper" / "voices" / "en" / "en_US" / "amy" / "medium" / "model.onnx",
            Path.home() / ".local" / "share" / "piper" / "voices" / "en" / "en_US" / f"{voice_name}.onnx",
            Path("models") / "tts" / f"{voice_name}.onnx",
        ]
    else:
        possible_paths = [
            Path.home() / ".local" / "share" / "piper" / "voices" / voice_name.replace("-", "/") / "model.onnx",
            Path.home() / ".local" / "share" / "piper" / "voices" / voice_name / "model.onnx",
            Path("models") / "tts" / f"{voice_name}.onnx",
        ]
    
    for path in possible_paths:
        if path.exists():
            return True
    return False

def check_piper_voice_hf(model_id: str) -> bool:
    """HuggingFace Piper ìŒì„± ëª¨ë¸ í™•ì¸"""
    # íŒŒì¼ëª… ì¶”ì¶œ
    if model_id == "neurlang/piper-onnx-kss-korean":
        model_file = "piper-kss-korean.onnx"
        config_file = "piper-kss-korean.onnx.json"
    else:
        # ì¼ë°˜ì ì¸ ê²½ìš°
        model_name = model_id.split("/")[-1]
        file_prefix = model_name.replace("piper-onnx-", "piper-")
        model_file = f"{file_prefix}.onnx"
        config_file = f"{file_prefix}.onnx.json"
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸
    save_dir = Path("models") / "tts" / model_id.replace("/", "_")
    model_path = save_dir / model_file
    config_path = save_dir / config_file
    
    if model_path.exists() and config_path.exists():
        return True
    
    # HuggingFace ìºì‹œ í™•ì¸
    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
    if cache_dir.exists():
        model_name_safe = model_id.replace("/", "--")
        cache_model_dir = cache_dir / f"models--{model_name_safe}"
        if cache_model_dir.exists():
            # ìºì‹œì—ì„œ íŒŒì¼ ì°¾ê¸°
            cached_files = list(cache_model_dir.rglob("*.onnx"))
            if cached_files:
                return True
    
    return False

def load_config() -> dict:
    """config.yaml ë¡œë“œ"""
    config_path = Path("config.yaml")
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return {}

def scan_required_models() -> Dict[str, Dict]:
    """í•„ìš”í•œ ëª¨ë“  ëª¨ë¸ ìŠ¤ìº”"""
    config = load_config()
    
    models = {}
    
    # 1. LLM ëª¨ë¸
    llm_config = config.get("llm", {})
    llm_model = llm_config.get("model", "llama-3.1-8b")
    llm_path = llm_config.get("model_path")
    
    if llm_model == "llama-3.1-8b":
        model_id = "meta-llama/Llama-3.1-8B-Instruct"
        local_path = llm_path or "models/llm/llama-3.1-8b"
    elif llm_model == "deepseek-r1-7b":
        model_id = "deepseek-ai/DeepSeek-R1"
        local_path = llm_path or "models/llm/deepseek-r1-7b"
    else:
        model_id = "meta-llama/Llama-3.1-8B-Instruct"
        local_path = llm_path or "models/llm/llama-3.1-8b"
    
    models["llm"] = {
        "name": f"LLM ({llm_model})",
        "model_id": model_id,
        "local_path": local_path,
        "size": "~16GB",
        "exists": check_model_exists(local_path) or check_model_exists(model_id),
        "required": True
    }
    
    # 2. Whisper ëª¨ë¸
    whisper_config = config.get("whisper", {})
    whisper_model = whisper_config.get("model", "openai/whisper-large-v3")
    
    # HuggingFace ëª¨ë¸ IDì¸ì§€ í™•ì¸
    is_hf_model = "/" in whisper_model
    
    if is_hf_model:
        # HuggingFace ëª¨ë¸
        models["whisper"] = {
            "name": f"Whisper ({whisper_model})",
            "model_id": whisper_model,
            "local_path": None,  # HuggingFace ìºì‹œ
            "size": "~3GB",
            "exists": check_model_exists(whisper_model),
            "required": True
        }
    else:
        # ê¸°ì¡´ whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë¸
        models["whisper"] = {
            "name": f"Whisper ({whisper_model})",
            "model_id": whisper_model,
            "local_path": None,  # WhisperëŠ” ìë™ ìºì‹œ
            "size": "~3GB",
            "exists": check_whisper_model(whisper_model),
            "required": True
        }
    
    # 3. TTS ëª¨ë¸
    tts_config = config.get("tts", {})
    tts_model = tts_config.get("model", "piper")
    
    if tts_model == "piper":
        # í•œêµ­ì–´ ìŒì„±
        ko_voice = tts_config.get("piper", {}).get("voice", "neurlang/piper-onnx-kss-korean")
        
        # HuggingFace ëª¨ë¸ IDì¸ì§€ í™•ì¸
        is_hf_model = "/" in ko_voice and ko_voice.count("/") == 1
        
        if is_hf_model:
            # HuggingFace ëª¨ë¸
            models["tts_korean"] = {
                "name": f"Piper í•œêµ­ì–´ ({ko_voice})",
                "model_id": ko_voice,  # "neurlang/piper-onnx-kss-korean"
                "local_path": None,
                "size": "~10MB",
                "exists": check_piper_voice_hf(ko_voice),
                "required": True,
                "is_huggingface": True
            }
        else:
            # ê¸°ì¡´ rhasspy ëª¨ë¸
            models["tts_korean"] = {
                "name": f"Piper í•œêµ­ì–´ ({ko_voice})",
                "model_id": f"rhasspy/piper-voices/{ko_voice}",
                "local_path": None,
                "size": "~10MB",
                "exists": check_piper_voice(ko_voice),
                "required": True,
                "is_huggingface": False
            }
        
        # ì˜ì–´ ìŒì„± (ë¹„ë””ì˜¤ ìƒì„±ìš©)
        # HuggingFaceì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ: rhasspy/piper-voicesì˜ en/en_US/amy/medium ê²½ë¡œ
        models["tts_english"] = {
            "name": "Piper ì˜ì–´ (en_US-amy-medium)",
            "model_id": "rhasspy/piper-voices",  # ì „ì²´ ë¦¬í¬ì§€í† ë¦¬
            "local_path": None,
            "size": "~10MB",
            "exists": check_piper_voice("en_US-amy-medium"),
            "required": True,
            "voice_name": "en_US-amy-medium",  # ì‹¤ì œ ìŒì„± ì´ë¦„
            "voice_path": "en/en_US/amy/medium"  # HuggingFace ë‚´ ê²½ë¡œ
        }
    elif tts_model == "vibevoice":
        vibevoice_id = tts_config.get("vibevoice", {}).get("model_id", "microsoft/VibeVoice-1.5B")
        models["tts_vibevoice"] = {
            "name": "VibeVoice-1.5B",
            "model_id": vibevoice_id,
            "local_path": None,
            "size": "~5.4GB",
            "exists": check_model_exists(vibevoice_id),
            "required": True
        }
    
    # 4. Stable Diffusion XL
    video_gen_config = config.get("video_generation", {})
    if video_gen_config.get("model") == "svd" or video_gen_config.get("use_image_generation"):
        models["sdxl"] = {
            "name": "Stable Diffusion XL",
            "model_id": "stabilityai/stable-diffusion-xl-base-1.0",
            "local_path": None,
            "size": "~7GB",
            "exists": check_model_exists("stabilityai/stable-diffusion-xl-base-1.0"),
            "required": True
        }
        
        # 5. Stable Video Diffusion
        models["svd"] = {
            "name": "Stable Video Diffusion",
            "model_id": "stabilityai/stable-video-diffusion-img2vid",
            "local_path": None,
            "size": "~17GB",
            "exists": check_model_exists("stabilityai/stable-video-diffusion-img2vid"),
            "required": True
        }
    
    return models

def download_model(model_info: Dict, index: int, total: int) -> bool:
    """ë‹¨ì¼ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    name = model_info["name"]
    model_id = model_info["model_id"]
    local_path = model_info.get("local_path")
    size = model_info.get("size", "ì•Œ ìˆ˜ ì—†ìŒ")
    
    print(f"\n{'='*60}")
    print(f"[{index}/{total}] {name} ë‹¤ìš´ë¡œë“œ ì¤‘...")
    print(f"í¬ê¸°: {size}")
    print(f"{'='*60}\n")
    
    try:
        # HuggingFace CLI ëª…ë ¹ì–´ êµ¬ì„±
        cmd = ["huggingface-cli", "download", model_id]
        
        if local_path:
            Path(local_path).mkdir(parents=True, exist_ok=True)
            cmd.extend(["--local-dir", local_path, "--local-dir-use-symlinks", "False"])


        
        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        result = subprocess.run(
            cmd,
            check=True,
            text=True
        )
        
        # ì €ì¥ ìœ„ì¹˜ í‘œì‹œ
        if local_path:
            save_location = str(Path(local_path).absolute())
        else:
            # HuggingFace ê¸°ë³¸ ìºì‹œ ìœ„ì¹˜
            cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
            model_name_safe = model_id.replace("/", "--")
            save_location = str(cache_dir / f"models--{model_name_safe}")
        
        print(f"\nâœ… {name} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_location}")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ {name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  {name} ë‹¤ìš´ë¡œë“œê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return False
    except FileNotFoundError:
        print("\nâŒ huggingface-clië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("  pip install huggingface-hub")
        return False

def download_whisper_model(model_name: str, index: int, total: int) -> bool:
    """Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (HuggingFace CLI ì‚¬ìš©)"""
    print(f"\n{'='*60}")
    print(f"[{index}/{total}] Whisper ({model_name}) ë‹¤ìš´ë¡œë“œ ì¤‘...")
    print(f"í¬ê¸°: ~3GB")
    print(f"{'='*60}\n")
    
    # HuggingFace ëª¨ë¸ IDì¸ ê²½ìš°
    if "/" in model_name:
        try:
            cmd = ["huggingface-cli", "download", model_name]
            result = subprocess.run(cmd, check=True, text=True)
            
            # ì €ì¥ ìœ„ì¹˜ í‘œì‹œ (HuggingFace ê¸°ë³¸ ìºì‹œ)
            cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
            model_name_safe = model_name.replace("/", "--")
            save_location = str(cache_dir / f"models--{model_name_safe}")
            
            print(f"\nâœ… Whisper ({model_name}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_location}")
            return True
        except FileNotFoundError:
            print("\nâŒ huggingface-clië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("  pip install huggingface-hub")
            return False
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ Whisper ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    else:
        # ê¸°ì¡´ whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë¸ (fallback)
        try:
            import whisper
            print("Whisper ëª¨ë¸ ë¡œë“œ ì¤‘ (ìë™ ë‹¤ìš´ë¡œë“œ)...")
            model = whisper.load_model(model_name)
            print(f"\nâœ… Whisper ({model_name}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            return True
        except Exception as e:
            print(f"\nâŒ Whisper ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

def download_piper_voice_english(voice_name: str, voice_path: str, index: int, total: int) -> bool:
    """Piper ì˜ì–´ ìŒì„± ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (HuggingFace CLI ì‚¬ìš©)"""
    print(f"\n{'='*60}")
    print(f"[{index}/{total}] Piper ì˜ì–´ ìŒì„± ({voice_name}) ë‹¤ìš´ë¡œë“œ ì¤‘...")
    print(f"í¬ê¸°: ~10MB")
    print(f"{'='*60}\n")
    
    try:
        from huggingface_hub import hf_hub_download
        
        repo_id = "rhasspy/piper-voices"
        # ì •í™•í•œ íŒŒì¼ëª… ì‚¬ìš© (en_US-amy-medium.onnx, en_US-amy-medium.onnx.json)
        model_filename = f"{voice_name}.onnx"
        config_filename = f"{voice_name}.onnx.json"
        model_file = f"{voice_path}/{model_filename}"
        config_file = f"{voice_path}/{config_filename}"
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ (Piper í‘œì¤€ ê²½ë¡œ)
        save_dir = Path.home() / ".local" / "share" / "piper" / "voices" / voice_path
        save_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘: {repo_id}/{model_file}")
        
        # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        print(f"ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_filename}")
        print(f"ì €ì¥ ë””ë ‰í† ë¦¬: {save_dir}")
        
        downloaded_model = hf_hub_download(
            repo_id=repo_id,
            filename=model_file,
            local_dir=str(save_dir),
            local_dir_use_symlinks=False
        )
        
        # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ í™•ì¸
        downloaded_model_path = Path(downloaded_model)
        target_model_path = save_dir / model_filename
        
        print(f"ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ: {downloaded_model_path}")
        print(f"ëª©í‘œ íŒŒì¼ ê²½ë¡œ: {target_model_path}")
        
        # íŒŒì¼ì´ ë‹¤ë¥¸ ìœ„ì¹˜ì— ë‹¤ìš´ë¡œë“œëœ ê²½ìš° ì´ë™
        if downloaded_model_path != target_model_path:
            if downloaded_model_path.exists() and not target_model_path.exists():
                import shutil
                shutil.move(str(downloaded_model_path), str(target_model_path))
                print(f"âœ… ëª¨ë¸ íŒŒì¼ ì´ë™ ì™„ë£Œ: {target_model_path}")
            elif target_model_path.exists():
                print(f"âœ… ëª¨ë¸ íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {target_model_path}")
            else:
                print(f"âš ï¸  íŒŒì¼ ìœ„ì¹˜ í™•ì¸ í•„ìš”: {downloaded_model_path}")
        else:
            print(f"âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target_model_path}")
        
        # ìµœì¢… íŒŒì¼ ì¡´ì¬ í™•ì¸
        if target_model_path.exists():
            print(f"âœ… ìµœì¢… í™•ì¸: ëª¨ë¸ íŒŒì¼ ì¡´ì¬ - {target_model_path}")
        else:
            print(f"âš ï¸  ê²½ê³ : ëª©í‘œ ê²½ë¡œì— íŒŒì¼ ì—†ìŒ - {target_model_path}")
            if downloaded_model_path.exists():
                print(f"   ëŒ€ì‹  ì´ ê²½ë¡œì— ìˆìŒ: {downloaded_model_path}")
        
        # Config íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        print(f"Config íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘: {config_filename}")
        downloaded_config = hf_hub_download(
            repo_id=repo_id,
            filename=config_file,
            local_dir=str(save_dir),
            local_dir_use_symlinks=False
        )
        
        # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™ (í•„ìš”ì‹œ)
        downloaded_config_path = Path(downloaded_config)
        target_config_path = save_dir / config_filename
        if downloaded_config_path != target_config_path and downloaded_config_path.exists():
            # íŒŒì¼ì´ ë‹¤ë¥¸ ìœ„ì¹˜ì— ë‹¤ìš´ë¡œë“œëœ ê²½ìš° ì´ë™
            if not target_config_path.exists():
                import shutil
                shutil.move(str(downloaded_config_path), str(target_config_path))
                print(f"âœ… Config íŒŒì¼ ì´ë™ ì™„ë£Œ: {target_config_path}")
            else:
                print(f"âœ… Config íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target_config_path}")
        else:
            print(f"âœ… Config íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {downloaded_config_path}")
        
        # ìµœì¢… í™•ì¸
        final_model_path = target_model_path if target_model_path.exists() else downloaded_model_path
        final_config_path = target_config_path if target_config_path.exists() else downloaded_config_path
        
        print(f"\nâœ… Piper ì˜ì–´ ìŒì„± ({voice_name}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print(f"ì €ì¥ ìœ„ì¹˜: {save_dir}")
        print(f"ëª¨ë¸ íŒŒì¼: {final_model_path}")
        print(f"  ì¡´ì¬ ì—¬ë¶€: {final_model_path.exists()}")
        print(f"Config íŒŒì¼: {final_config_path}")
        print(f"  ì¡´ì¬ ì—¬ë¶€: {final_config_path.exists()}")
        
        if not final_model_path.exists():
            print(f"\nâš ï¸  ê²½ê³ : ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print(f"ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í™•ì¸: {downloaded_model_path}")
        
        return True
        
    except ImportError:
        print("\nâš ï¸  huggingface_hub íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("huggingface-clië¡œ ëŒ€ì²´ ë‹¤ìš´ë¡œë“œ ì‹œë„ ì¤‘...")
        try:
            # huggingface-clië¡œ íŠ¹ì • íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            repo_id = "rhasspy/piper-voices"
            save_dir = Path.home() / ".local" / "share" / "piper" / "voices" / voice_path
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # ì „ì²´ ë¦¬í¬ì§€í† ë¦¬ ë‹¤ìš´ë¡œë“œ (ì¼ë¶€ë§Œ í•„ìš”í•˜ì§€ë§Œ)
            cmd = ["huggingface-cli", "download", repo_id, "--include", f"{voice_path}/*", "--local-dir", str(save_dir.parent.parent.parent.parent), "--local-dir-use-symlinks", "False"]
            result = subprocess.run(cmd, check=True, text=True)
            
            print(f"\nâœ… Piper ì˜ì–´ ìŒì„± ({voice_name}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print(f"ì €ì¥ ìœ„ì¹˜: {save_dir}")
            return True
        except Exception as e:
            print(f"\nâŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            print(f"\nìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ë°©ë²•:")
            print(f"  https://huggingface.co/{repo_id}/tree/main/{voice_path}")
            return False
    except Exception as e:
        print(f"\nâŒ HuggingFace ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def download_piper_voice(voice_name: str, index: int, total: int, is_huggingface: bool = False) -> bool:
    """Piper ìŒì„± ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (HuggingFace CLI ì‚¬ìš©)"""
    print(f"\n{'='*60}")
    print(f"[{index}/{total}] Piper ìŒì„± ({voice_name}) ë‹¤ìš´ë¡œë“œ ì¤‘...")
    print(f"í¬ê¸°: ~10MB")
    print(f"{'='*60}\n")
    
    # HuggingFace ëª¨ë¸ì¸ ê²½ìš°
    if is_huggingface or "/" in voice_name:
        try:
            model_id = voice_name
            print(f"HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_id}")
            
            # ì €ì¥ ë””ë ‰í† ë¦¬
            save_dir = Path("models") / "tts" / model_id.replace("/", "_")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # huggingface-clië¡œ ë‹¤ìš´ë¡œë“œ
            cmd = ["huggingface-cli", "download", model_id, "--local-dir", str(save_dir), "--local-dir-use-symlinks", "False"]
            result = subprocess.run(cmd, check=True, text=True)
            
            print(f"\nâœ… Piper ìŒì„± ({voice_name}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print(f"ì €ì¥ ìœ„ì¹˜: {save_dir}")
            return True
            
        except FileNotFoundError:
            print("\nâŒ huggingface-clië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("  pip install huggingface-hub")
            return False
        except Exception as e:
            print(f"\nâŒ HuggingFace ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    else:
        # ê¸°ì¡´ rhasspy ëª¨ë¸
        try:
            # piper ëª…ë ¹ì–´ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œë„
            cmd = ["piper", "download", "--voice", voice_name]
            result = subprocess.run(cmd, check=True, text=True, capture_output=True)
            print(f"\nâœ… Piper ìŒì„± ({voice_name}) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            return True
        except (FileNotFoundError, subprocess.CalledProcessError):
            # ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
            print(f"\nâš ï¸  Piper ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ:")
            print(f"  https://huggingface.co/rhasspy/piper-voices/tree/main/{voice_name}")
            print(f"ë˜ëŠ”:")
            print(f"  python -m piper.download --voice {voice_name}")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description="ëª¨ë¸ ìŠ¤ìº” ë° ë‹¤ìš´ë¡œë“œ ë„êµ¬")
    parser.add_argument(
        "--auto", "-y",
        action="store_true",
        help="ìë™ ëª¨ë“œ: ëª¨ë“  í™•ì¸ ì—†ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì§„í–‰"
    )
    parser.add_argument(
        "--force", "-f",
        action="store_true",
        help="ê°•ì œ ëª¨ë“œ: ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ"
    )
    args = parser.parse_args()
    auto_mode = args.auto
    force_mode = args.force
    
    print("=" * 60)
    print("ëª¨ë¸ ìŠ¤ìº” ë° ë‹¤ìš´ë¡œë“œ ë„êµ¬")
    if auto_mode:
        print("ğŸ¤– ìë™ ëª¨ë“œ: ëª¨ë“  í™•ì¸ ì—†ì´ ìë™ ì§„í–‰")
    if force_mode:
        print("ğŸ”„ ê°•ì œ ëª¨ë“œ: ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ")
    print("=" * 60)
    
    print("\ní•„ìš”í•œ ëª¨ë¸ì„ ìŠ¤ìº” ì¤‘...\n")
    
    # ëª¨ë¸ ìŠ¤ìº”
    models = scan_required_models()
    
    # ì—†ëŠ” ëª¨ë¸ í•„í„°ë§ (ê°•ì œ ëª¨ë“œë©´ ëª¨ë“  ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ëŒ€ìƒìœ¼ë¡œ)
    if force_mode:
        missing_models = models
        existing_models = {}
    else:
        missing_models = {k: v for k, v in models.items() if not v["exists"]}
        existing_models = {k: v for k, v in models.items() if v["exists"]}
    
    # ê²°ê³¼ ì¶œë ¥
    print("=" * 60)
    print("ëª¨ë¸ ìƒíƒœ")
    print("=" * 60)
    
    if existing_models:
        print("\nâœ… ì´ë¯¸ ì„¤ì¹˜ëœ ëª¨ë¸:")
        for key, info in existing_models.items():
            print(f"  âœ“ {info['name']}")
    
    if missing_models:
        print(f"\nâŒ ë‹¤ìš´ë¡œë“œ í•„ìš”í•œ ëª¨ë¸ ({len(missing_models)}ê°œ):")
        for i, (key, info) in enumerate(missing_models.items(), 1):
            print(f"  {i}. {info['name']} ({info['size']})")
    else:
        print("\nâœ… ëª¨ë“  í•„ìš”í•œ ëª¨ë¸ì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        return
    
    # ë‹¤ìš´ë¡œë“œ í™•ì¸ ë° ì„ íƒ
    if missing_models:
        print("\n" + "=" * 60)
        total_size = sum(
            float(info["size"].replace("~", "").replace("GB", "").replace("MB", "")) 
            for info in missing_models.values() 
            if "GB" in info["size"] or "MB" in info["size"]
        )
        print(f"ì˜ˆìƒ ì´ ë‹¤ìš´ë¡œë“œ í¬ê¸°: ~{total_size:.1f}GB")
        print("=" * 60)
        
        if auto_mode:
            # ìë™ ëª¨ë“œ: ëª¨ë“  ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
            print("\nğŸ¤– ìë™ ëª¨ë“œ: ëª¨ë“  ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
            selected_models = missing_models
        else:
            print("\në‹¤ìš´ë¡œë“œ ì˜µì…˜:")
            print("1. ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìë™)")
            print("2. ëª¨ë¸ë³„ ì„ íƒ ë‹¤ìš´ë¡œë“œ")
            print("3. ì·¨ì†Œ")
            
            choice = input("\nì„ íƒ (1/2/3): ").strip()
            
            if choice == "3":
                print("\në‹¤ìš´ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
            elif choice == "2":
                # ëª¨ë¸ë³„ ì„ íƒ
                selected_models = {}
                print("\në‹¤ìš´ë¡œë“œí•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš” (ë²ˆí˜¸ ì…ë ¥, ì—¬ëŸ¬ ê°œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„, 'all'ì€ ëª¨ë‘ ì„ íƒ):")
                for i, (key, info) in enumerate(missing_models.items(), 1):
                    print(f"  {i}. {info['name']} ({info['size']})")
                
                selection = input("\nì„ íƒ: ").strip()
                
                if selection.lower() == "all":
                    selected_models = missing_models
                else:
                    try:
                        indices = [int(x.strip()) for x in selection.split(",")]
                        model_list = list(missing_models.items())
                        for idx in indices:
                            if 1 <= idx <= len(model_list):
                                key, info = model_list[idx - 1]
                                selected_models[key] = info
                    except ValueError:
                        print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
                        return
                    
                    if not selected_models:
                        print("âŒ ì„ íƒëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                        return
            else:
                # ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
                selected_models = missing_models
        
        if not selected_models:
            print("\në‹¤ìš´ë¡œë“œí•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nì„ íƒëœ ëª¨ë¸ ({len(selected_models)}ê°œ):")
        for info in selected_models.values():
            print(f"  - {info['name']} ({info['size']})")
        
        if not auto_mode:
            response = input("\në‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if response != 'y':
                print("\në‹¤ìš´ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
        else:
            print("\nğŸ¤– ìë™ ëª¨ë“œ: ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # selected_modelsë¥¼ missing_modelsë¡œ ì—…ë°ì´íŠ¸
        missing_models = selected_models
        
        # ìˆœì°¨ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
        print("\n" + "=" * 60)
        print("ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        print("=" * 60)
        print("\nâš ï¸  ì¤‘ë‹¨(Ctrl+C)í•´ë„ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
        
        total = len(missing_models)
        success_count = 0
        failed_models = []
        
        for i, (key, info) in enumerate(missing_models.items(), 1):
            try:
                if key == "whisper":
                    success = download_whisper_model(info["model_id"], i, total)
                elif key.startswith("tts_") and "piper" in key:
                    # ì˜ì–´ ìŒì„±ì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                    if key == "tts_english":
                        voice_name = info.get("voice_name", "en_US-amy-medium")
                        voice_path = info.get("voice_path", "en/en_US/amy/medium")
                        success = download_piper_voice_english(voice_name, voice_path, i, total)
                    else:
                        voice_name = info["model_id"]
                        is_hf = info.get("is_huggingface", False) or "/" in voice_name
                        success = download_piper_voice(voice_name, i, total, is_huggingface=is_hf)
                elif key == "tts_vibevoice":
                    # VibeVoiceëŠ” ì¼ë°˜ HuggingFace ëª¨ë¸
                    success = download_model(info, i, total)
                else:
                    success = download_model(info, i, total)
                
                if success:
                    success_count += 1
                else:
                    failed_models.append(info['name'])
                    print(f"\nâš ï¸  {info['name']} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                    if auto_mode:
                        print("ğŸ¤– ìë™ ëª¨ë“œ: ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
                    else:
                        response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                        if response != 'y':
                            print("\në‹¤ìš´ë¡œë“œê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            break
            except KeyboardInterrupt:
                print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ {info['name']} ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                failed_models.append(info['name'])
                if auto_mode:
                    print("ğŸ¤– ìë™ ëª¨ë“œ: ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
                else:
                    response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                    if response != 'y':
                        break
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        print("=" * 60)
        print(f"\nì„±ê³µ: {success_count}/{total}")
        print(f"ì‹¤íŒ¨: {total - success_count}/{total}")
        
        if failed_models:
            print("\nì‹¤íŒ¨í•œ ëª¨ë¸:")
            for name in failed_models:
                print(f"  - {name}")
        
        if success_count == total:
            print("\nâœ… ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print("\nì´ì œ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print("  python main.py")
        else:
            print("\nâš ï¸  ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            print("ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ë‚¨ì€ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print("  python download_all_models.py")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
